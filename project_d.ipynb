{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a81a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2eb0f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42bb32d",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ca68b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('new2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77f7517d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>every break, you must be nervous, like somethi...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status\n",
       "0           0                                         oh my gosh  Anxiety\n",
       "1           1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3           3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4           4  I'm restless and restless, it's been a month n...  Anxiety\n",
       "5           5  every break, you must be nervous, like somethi...  Anxiety"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1df10679",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"Unnamed: 0\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c259df",
   "metadata": {},
   "source": [
    "# preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be9839ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20492\\1256883032.py:10: SyntaxWarning: invalid escape sequence '\\['\n",
      "  text=re.sub('\\[.*?\\]','',text)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hi name aryan hobby plraying croicket'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "sw=set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('\\[.*?\\]','',text)\n",
    "     \n",
    "    words=text.split()  \n",
    "    words=[word for word in words if word not in sw]\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "data[\"statement\"]=data[\"statement\"].fillna(\"\").apply(preprocess_text)\n",
    "\n",
    "preprocess_text(\"hi MY name is aryan my hobby is plraying croicket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "50b9be76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Normal                  16351\n",
       "Depression              15404\n",
       "Suicidal                10653\n",
       "Anxiety                  3888\n",
       "Bipolar                  2877\n",
       "Stress                   2669\n",
       "Personality disorder     1201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1f08885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "deaa5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"]=label.fit_transform(data['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d12faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[\"statement\"]\n",
    "y=data[\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "62c7f152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42434,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af616bd6",
   "metadata": {},
   "source": [
    "## tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eb625cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer,BertForSequenceClassification,Trainer,TrainingArguments\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2fc2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoding=tokenizer(list(x),padding=True,truncation=True,max_length=200)\n",
    "test_encoding=tokenizer(list(y),padding=True,truncation=True,max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4ed388df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=Dataset.from_dict({\"input_ids\":train_encoding[\"input_ids\"], 'attention_mask':train_encoding['attention_mask'],\"label\":x.tolist()})\n",
    "\n",
    "test_dataset=Dataset.from_dict({\"input_ids\":test_encoding[\"input_ids\"], 'attention_mask':test_encoding['attention_mask'],\"label\":y.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ab27b4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 10089, 102, 0],\n",
       " 'attention_mask': [1, 1, 1, 0],\n",
       " 'label': 'Anxiety'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "78ec9c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "676ba29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments module: transformers.training_args\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'TrainingArguments' has no attribute '__file__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrainingArguments module:\u001b[39m\u001b[33m\"\u001b[39m, TrainingArguments.\u001b[34m__module__\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrainingArguments file:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mTrainingArguments\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__file__\u001b[39;49m)\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'TrainingArguments' has no attribute '__file__'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "print(\"TrainingArguments module:\", TrainingArguments.__module__)\n",
    "print(\"TrainingArguments file:\", TrainingArguments.__file__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46b365",
   "metadata": {},
   "source": [
    "# fine tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "11eec812",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e1208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'batch_eval_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model= BertForSequenceClassification.from_pretrained(\u001b[33m'\u001b[39m\u001b[33mbert-base-uncased\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m trainer=\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:432\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    430\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo `TrainingArguments` passed, using `output_dir=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    431\u001b[39m     args = TrainingArguments(output_dir=output_dir)\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_eval_metrics\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m compute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcompute_result\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(compute_metrics).parameters:\n\u001b[32m    434\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    435\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mWhen using `batch_eval_metrics`, your `compute_metrics` function must take a `compute_result`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    436\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m boolean argument which will be triggered after the last batch of the eval set to signal that the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    437\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m summary statistics should be returned by the function.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    438\u001b[39m         )\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'batch_eval_metrics'"
     ]
    }
   ],
   "source": [
    "model= BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "trainer=Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    \n",
    "    \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
